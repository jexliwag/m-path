{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy Crash Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_ner_bc5cdr_md as ner\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = ner.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Caffeine is metabolized into paraxanthine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word in doc is tokenized (turned into tokens) when passed to the `nlp` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caffeine\n",
      "is\n",
      "metabolized\n",
      "into\n",
      "paraxanthine\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linguistic Features\n",
    "Each token has built in linguistic features, including:\n",
    "-   text (original word text)\n",
    "-   lemma_ (base form of the word)\n",
    "-   pos_ (simple part-of-speech)\n",
    "-   dep_ (syntactic dependency)\n",
    "-   is_punct (boolean, token is a punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caffeine caffeine NOUN nsubjpass False\n",
      "is be AUX auxpass False\n",
      "metabolized metabolize VERB ROOT False\n",
      "into into ADP case False\n",
      "paraxanthine paraxanthine NOUN nmod False\n",
      ". . PUNCT punct True\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.dep_, token.is_punct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Matching\n",
    "spaCy has a built-in token matching engine called `Matcher` that can recognize phrases with the given linguistic patterns. Consider the example sentence below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 =  nlp(\"The family received an apple, a sack of rice, and bananas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance we want to get all mentions of phrases with the pattern: `article` `noun`. We can do so by adding the pattern in the matcher engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\":\"DET\"},{'POS': 'NOUN'}]\n",
    "matcher.add('CAND', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The family\n",
      "an apple\n",
      "a sack\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc2)\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc2[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
